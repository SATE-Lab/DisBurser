18:08:50.489 [main] INFO  io.redit.execution.RuntimeEngine - Waiting for event E1 ...
18:08:50.775 [main] INFO  io.redit.execution.RuntimeEngine - Sending test case event E1 ...
18:08:50.967 [qtp1545242146-22] INFO  io.redit.execution.EventService - Event E1 received!
18:08:50.968 [main] INFO  io.redit.execution.RuntimeEngine - Waiting for event E2 ...
18:08:50.999 [main] WARN  o.a.h.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
18:08:51.110 [main] INFO  o.a.h.m.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
18:08:51.110 [main] INFO  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system started
18:08:51.118 [main] WARN  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
18:08:51.172 [main] INFO  o.a.hadoop.tools.SimpleCopyListing - Starting: Building listing using multi threaded approach for hdfs://mycluster/source
18:08:51.175 [main] INFO  o.a.hadoop.tools.SimpleCopyListing - Building listing using multi threaded approach for hdfs://mycluster/source: duration 0:00.003s
18:08:51.177 [main] INFO  o.a.hadoop.tools.SimpleCopyListing - Paths (files+dirs) cnt = 2; dirCnt = 1
18:08:51.177 [main] INFO  o.a.hadoop.tools.SimpleCopyListing - Build file listing completed.
18:08:51.177 [main] INFO  o.a.h.conf.Configuration.deprecation - io.sort.mb is deprecated. Instead, use mapreduce.task.io.sort.mb
18:08:51.177 [main] INFO  o.a.h.conf.Configuration.deprecation - io.sort.factor is deprecated. Instead, use mapreduce.task.io.sort.factor
18:08:51.191 [main] INFO  org.apache.hadoop.tools.DistCp - Number of paths in the copy list: 2
18:08:51.194 [main] INFO  org.apache.hadoop.tools.DistCp - Number of paths in the copy list: 2
18:08:51.195 [main] WARN  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
18:08:51.205 [main] WARN  o.a.h.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
18:08:51.224 [main] INFO  o.a.hadoop.mapreduce.JobSubmitter - number of splits:1
18:08:51.262 [main] INFO  o.a.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1117182963_0001
18:08:51.262 [main] INFO  o.a.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
18:08:51.315 [main] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
18:08:51.315 [main] INFO  org.apache.hadoop.tools.DistCp - DistCp job-id: job_local1117182963_0001
18:08:51.316 [main] INFO  org.apache.hadoop.mapreduce.Job - Running job: job_local1117182963_0001
18:08:51.316 [Thread-61] INFO  o.a.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
18:08:51.319 [Thread-61] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 2
18:08:51.319 [Thread-61] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18:08:51.319 [Thread-61] INFO  o.a.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
18:08:51.335 [Thread-61] INFO  o.a.hadoop.mapred.LocalJobRunner - Waiting for map tasks
18:08:51.336 [LocalJobRunner Map Task Executor #0] INFO  o.a.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1117182963_0001_m_000000_0
18:08:51.344 [LocalJobRunner Map Task Executor #0] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 2
18:08:51.344 [LocalJobRunner Map Task Executor #0] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18:08:51.354 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
18:08:51.356 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: file:/tmp/hadoop/mapred/staging/zdc944354243/.staging/_distcp495645634/fileList.seq:0+356
18:08:51.359 [LocalJobRunner Map Task Executor #0] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 2
18:08:51.359 [LocalJobRunner Map Task Executor #0] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18:08:51.366 [LocalJobRunner Map Task Executor #0] INFO  o.a.hadoop.tools.mapred.CopyMapper - Copying hdfs://mycluster/source/data to hdfs://mycluster/target/data
18:08:51.381 [LocalJobRunner Map Task Executor #0] INFO  o.a.hadoop.tools.mapred.CopyMapper - Copying hdfs://mycluster/source/data/f1 to hdfs://mycluster/target/data/f1
18:08:51.384 [LocalJobRunner Map Task Executor #0] INFO  o.a.h.t.m.RetriableFileCopyCommand - Copying hdfs://mycluster/source/data/f1 to hdfs://mycluster/target/data/f1
18:08:51.384 [LocalJobRunner Map Task Executor #0] INFO  o.a.h.t.m.RetriableFileCopyCommand - Creating temp file: hdfs://mycluster/target/.distcp.tmp.attempt_local1117182963_0001_m_000000_0.1700474931384
18:08:51.384 [LocalJobRunner Map Task Executor #0] INFO  o.a.h.t.m.RetriableFileCopyCommand - Writing to temporary target file path hdfs://mycluster/target/.distcp.tmp.attempt_local1117182963_0001_m_000000_0.1700474931384
18:08:51.410 [LocalJobRunner Map Task Executor #0] INFO  o.a.h.t.m.RetriableFileCopyCommand - Renaming temporary target file path hdfs://mycluster/target/.distcp.tmp.attempt_local1117182963_0001_m_000000_0.1700474931384 to hdfs://mycluster/target/data/f1
18:08:51.423 [LocalJobRunner Map Task Executor #0] INFO  o.a.h.t.m.RetriableFileCopyCommand - Completed writing hdfs://mycluster/target/data/f1 (0 bytes)
18:08:51.430 [LocalJobRunner Map Task Executor #0] INFO  o.a.hadoop.mapred.LocalJobRunner -
18:08:51.432 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1117182963_0001_m_000000_0 is done. And is in the process of committing
18:08:51.433 [LocalJobRunner Map Task Executor #0] INFO  o.a.hadoop.mapred.LocalJobRunner -
18:08:51.433 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1117182963_0001_m_000000_0 is allowed to commit now
18:08:51.433 [LocalJobRunner Map Task Executor #0] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_local1117182963_0001_m_000000_0' to file:/tmp/hadoop/mapred/staging/zdc944354243/.staging/_distcp495645634/_logs
18:08:51.434 [LocalJobRunner Map Task Executor #0] INFO  o.a.hadoop.mapred.LocalJobRunner - Copying hdfs://mycluster/source/data/f1 to hdfs://mycluster/target/data/f1
18:08:51.434 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1117182963_0001_m_000000_0' done.
18:08:51.437 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1117182963_0001_m_000000_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=159496
		FILE: Number of bytes written=773961
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=0
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=2
		Map output records=0
		Input split bytes=148
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=425721856
	File Input Format Counters
		Bytes Read=388
	File Output Format Counters
		Bytes Written=8
	DistCp Counters
		Bandwidth in Bytes=0
		Bytes Copied=0
		Bytes Expected=0
		Files Copied=1
		DIR_COPY=1
18:08:51.437 [LocalJobRunner Map Task Executor #0] INFO  o.a.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1117182963_0001_m_000000_0
18:08:51.438 [Thread-61] INFO  o.a.hadoop.mapred.LocalJobRunner - map task executor complete.
18:08:51.447 [Thread-61] INFO  o.a.h.tools.mapred.CopyCommitter - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/zdc944354243/.staging/_distcp495645634
18:08:52.317 [main] INFO  org.apache.hadoop.mapreduce.Job - Job job_local1117182963_0001 running in uber mode : false
18:08:52.318 [main] INFO  org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
18:08:52.319 [main] INFO  org.apache.hadoop.mapreduce.Job - Job job_local1117182963_0001 completed successfully
18:08:52.323 [main] INFO  org.apache.hadoop.mapreduce.Job - Counters: 26
	File System Counters
		FILE: Number of bytes read=159496
		FILE: Number of bytes written=773961
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=0
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=2
		Map output records=0
		Input split bytes=148
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=425721856
	File Input Format Counters
		Bytes Read=388
	File Output Format Counters
		Bytes Written=8
	DistCp Counters
		Bandwidth in Bytes=0
		Bytes Copied=0
		Bytes Expected=0
		Files Copied=1
		DIR_COPY=1
18:08:53.336 [main] INFO  io.redit.execution.RuntimeEngine - Sending test case event E2 ...
18:08:53.341 [qtp1545242146-51] INFO  io.redit.execution.EventService - Event E2 received!
18:08:53.342 [main] INFO  io.redit.execution.RuntimeEngine - Waiting for event E3 ...
18:08:54.360 [main] WARN  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
18:08:54.363 [main] WARN  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
18:08:54.424 [main] INFO  o.a.hadoop.tools.SimpleCopyListing - Starting: Building listing using multi threaded approach for /source/.snapshot/s2
18:08:54.425 [main] INFO  o.a.hadoop.tools.SimpleCopyListing - Building listing using multi threaded approach for /source/.snapshot/s2: duration 0:00.001s
18:08:54.428 [main] INFO  org.apache.hadoop.tools.DistCp - Number of paths in the copy list: 2
18:08:54.428 [main] WARN  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
18:08:54.431 [main] WARN  o.a.h.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
18:08:54.442 [main] INFO  o.a.hadoop.mapreduce.JobSubmitter - number of splits:1
18:08:54.451 [main] INFO  o.a.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local688488821_0002
18:08:54.451 [main] INFO  o.a.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
18:08:54.483 [main] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
18:08:54.483 [main] INFO  org.apache.hadoop.tools.DistCp - DistCp job-id: job_local688488821_0002
18:08:54.484 [main] INFO  org.apache.hadoop.mapreduce.Job - Running job: job_local688488821_0002
18:08:54.484 [Thread-106] INFO  o.a.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
18:08:54.484 [Thread-106] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 2
18:08:54.484 [Thread-106] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18:08:54.484 [Thread-106] INFO  o.a.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
18:08:54.488 [Thread-106] INFO  o.a.hadoop.mapred.LocalJobRunner - Waiting for map tasks
18:08:54.488 [LocalJobRunner Map Task Executor #0] INFO  o.a.hadoop.mapred.LocalJobRunner - Starting task: attempt_local688488821_0002_m_000000_0
18:08:54.488 [LocalJobRunner Map Task Executor #0] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 2
18:08:54.488 [LocalJobRunner Map Task Executor #0] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18:08:54.488 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
18:08:54.489 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: file:/tmp/hadoop/mapred/staging/zdc856698124/.staging/_distcp-1105738030/fileList.seq:0+382
18:08:54.489 [LocalJobRunner Map Task Executor #0] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 2
18:08:54.489 [LocalJobRunner Map Task Executor #0] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18:08:54.494 [LocalJobRunner Map Task Executor #0] INFO  o.a.hadoop.tools.mapred.CopyMapper - Copying hdfs://mycluster/source/.snapshot/s2/prod to hdfs://mycluster/target/prod
18:08:54.502 [LocalJobRunner Map Task Executor #0] INFO  o.a.hadoop.tools.mapred.CopyMapper - Copying hdfs://mycluster/source/.snapshot/s2/prod/f1 to hdfs://mycluster/target/prod/f1
18:08:54.503 [LocalJobRunner Map Task Executor #0] INFO  o.a.h.t.m.RetriableFileCopyCommand - Copying hdfs://mycluster/source/.snapshot/s2/prod/f1 to hdfs://mycluster/target/prod/f1
18:08:54.503 [LocalJobRunner Map Task Executor #0] INFO  o.a.h.t.m.RetriableFileCopyCommand - Creating temp file: hdfs://mycluster/target/.distcp.tmp.attempt_local688488821_0002_m_000000_0.1700474934503
18:08:54.503 [LocalJobRunner Map Task Executor #0] INFO  o.a.h.t.m.RetriableFileCopyCommand - Writing to temporary target file path hdfs://mycluster/target/.distcp.tmp.attempt_local688488821_0002_m_000000_0.1700474934503
18:08:54.518 [LocalJobRunner Map Task Executor #0] INFO  o.a.h.t.m.RetriableFileCopyCommand - Renaming temporary target file path hdfs://mycluster/target/.distcp.tmp.attempt_local688488821_0002_m_000000_0.1700474934503 to hdfs://mycluster/target/prod/f1
18:08:54.526 [LocalJobRunner Map Task Executor #0] INFO  o.a.h.t.m.RetriableFileCopyCommand - Completed writing hdfs://mycluster/target/prod/f1 (0 bytes)
18:08:54.527 [LocalJobRunner Map Task Executor #0] INFO  o.a.hadoop.mapred.LocalJobRunner -
18:08:54.527 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local688488821_0002_m_000000_0 is done. And is in the process of committing
18:08:54.527 [LocalJobRunner Map Task Executor #0] INFO  o.a.hadoop.mapred.LocalJobRunner -
18:08:54.527 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task attempt_local688488821_0002_m_000000_0 is allowed to commit now
18:08:54.528 [LocalJobRunner Map Task Executor #0] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_local688488821_0002_m_000000_0' to file:/tmp/hadoop/mapred/staging/zdc856698124/.staging/_distcp-1105738030/_logs
18:08:54.528 [LocalJobRunner Map Task Executor #0] INFO  o.a.hadoop.mapred.LocalJobRunner - Copying hdfs://mycluster/source/.snapshot/s2/prod/f1 to hdfs://mycluster/target/prod/f1
18:08:54.528 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local688488821_0002_m_000000_0' done.
18:08:54.528 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local688488821_0002_m_000000_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=318362
		FILE: Number of bytes written=1544658
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=0
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=35
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=18
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=2
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=425721856
	File Input Format Counters
		Bytes Read=414
	File Output Format Counters
		Bytes Written=8
	DistCp Counters
		Bandwidth in Bytes=0
		Bytes Copied=0
		Bytes Expected=0
		Files Copied=1
		DIR_COPY=1
18:08:54.528 [LocalJobRunner Map Task Executor #0] INFO  o.a.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local688488821_0002_m_000000_0
18:08:54.528 [Thread-106] INFO  o.a.hadoop.mapred.LocalJobRunner - map task executor complete.
18:08:54.533 [Thread-106] INFO  o.a.h.tools.mapred.CopyCommitter - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/zdc856698124/.staging/_distcp-1105738030
18:08:55.484 [main] INFO  org.apache.hadoop.mapreduce.Job - Job job_local688488821_0002 running in uber mode : false
18:08:55.484 [main] INFO  org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
18:08:55.484 [main] INFO  org.apache.hadoop.mapreduce.Job - Job job_local688488821_0002 completed successfully
18:08:55.485 [main] INFO  org.apache.hadoop.mapreduce.Job - Counters: 26
	File System Counters
		FILE: Number of bytes read=318362
		FILE: Number of bytes written=1544658
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=0
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=35
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=18
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=2
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=425721856
	File Input Format Counters
		Bytes Read=414
	File Output Format Counters
		Bytes Written=8
	DistCp Counters
		Bandwidth in Bytes=0
		Bytes Copied=0
		Bytes Expected=0
		Files Copied=1
		DIR_COPY=1
18:08:57.485 [main] INFO  i.redit.samples.hdfs14869.SampleTest - Files in /target:
18:08:57.486 [main] INFO  i.redit.samples.hdfs14869.SampleTest - hdfs://mycluster/target/data
18:08:57.486 [main] INFO  i.redit.samples.hdfs14869.SampleTest - hdfs://mycluster/target/prod
18:08:57.486 [main] INFO  io.redit.execution.RuntimeEngine - Sending test case event E3 ...
18:08:57.491 [qtp1545242146-23] INFO  io.redit.execution.EventService - Event E3 received!
